<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li > ul > li:not(:nth-child(2)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > ul > li:nth-child(1) > ul > li:nth-child(1) > ul > li:nth-child(2) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(3) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > ul > li:nth-child(1) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > ul > li:nth-child(1) > ul > li:nth-child(1) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > ul > li:nth-child(1) > ul > li:nth-child(1) > ul > li:nth-child(2) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(2) > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Getting start with ClickHouse Backend(v1.2.1) | Apache Gluten incubating</title> <meta name="generator" content="Jekyll v3.9.3" /> <meta property="og:title" content="Getting start with ClickHouse Backend(v1.2.1)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Gluten is a middle layer responsible for offloading JVM-based SQL engines’ execution to native engines." /> <meta property="og:description" content="Gluten is a middle layer responsible for offloading JVM-based SQL engines’ execution to native engines." /> <link rel="canonical" href="https://gluten.apache.org/archives/v1.2.1/docs/getting-started/clickhouse-backend/" /> <meta property="og:url" content="https://gluten.apache.org/archives/v1.2.1/docs/getting-started/clickhouse-backend/" /> <meta property="og:site_name" content="Apache Gluten incubating" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Getting start with ClickHouse Backend(v1.2.1)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Gluten is a middle layer responsible for offloading JVM-based SQL engines’ execution to native engines.","headline":"Getting start with ClickHouse Backend(v1.2.1)","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://gluten.apache.org/assets/images/gluten-logo-blue.png"}},"url":"https://gluten.apache.org/archives/v1.2.1/docs/getting-started/clickhouse-backend/"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> <div class="site-logo" role="img" aria-label="Apache Gluten incubating"></div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Documentations category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/" class="nav-list-link">Documentations</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Getting-Started category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/getting-started/" class="nav-list-link">Getting-Started</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/getting-started/velox-backend/" class="nav-list-link">Getting Start with Velox Backend</a></li><li class="nav-list-item"><a href="/docs/getting-started/clickhouse-backend/" class="nav-list-link">Getting start with ClickHouse Backend</a></li><li class="nav-list-item"><a href="/docs/getting-started/build-guide/" class="nav-list-link">Build Parameters for Velox Backend</a></li><li class="nav-list-item"><a href="/docs/getting-started/s3/" class="nav-list-link">Using S3 with Gluten</a></li><li class="nav-list-item"><a href="/docs/getting-started/gcs/" class="nav-list-link">Using GCS with Gluten</a></li><li class="nav-list-item"><a href="/docs/getting-started/abfs/" class="nav-list-link">Using ABFS with Gluten</a></li><li class="nav-list-item"><a href="/docs/getting-started/localcache/" class="nav-list-link">Velox Local Caching</a></li></ul></li><li class="nav-list-item"><a href="/docs/configuration/" class="nav-list-link">Configuration</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Developers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/developers/" class="nav-list-link">Developers</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/developers/how-to-use/" class="nav-list-link">How To Use Gluten</a></li><li class="nav-list-item"><a href="/docs/developers/new-to/" class="nav-list-link">New To Gluten</a></li><li class="nav-list-item"><a href="/docs/developers/microbenchmarks/" class="nav-list-link">Micro Benchmarks for Velox Backend</a></li><li class="nav-list-item"><a href="/docs/developers/cpp-code-style/" class="nav-list-link">CPP Code Style</a></li><li class="nav-list-item"><a href="/docs/developers/velox-function-dev/" class="nav-list-link">Velox Function Development</a></li><li class="nav-list-item"><a href="/docs/developers/docker-ubuntu/" class="nav-list-link">Docker script for Ubuntu 22.04/20.04</a></li><li class="nav-list-item"><a href="/docs/developers/docker-centos7/" class="nav-list-link">Docker script for CentOS 7</a></li><li class="nav-list-item"><a href="/docs/developers/docker-centos8/" class="nav-list-link">Docker script for CentOS 8</a></li><li class="nav-list-item"><a href="/docs/developers/substrait/" class="nav-list-link">Substrait Modifications</a></li><li class="nav-list-item"><a href="/docs/developers/how-to-release/" class="nav-list-link">How To Release</a></li><li class="nav-list-item"><a href="/docs/developers/how-to-security-scan/" class="nav-list-link">How To Scan Security issues</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Velox Backend category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/velox-backend/" class="nav-list-link">Velox Backend</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/velox-backend/support/" class="nav-list-link">Supported Operators & Functions</a></li><li class="nav-list-item"><a href="/docs/velox-backend/limitations/" class="nav-list-link">Limitations</a></li><li class="nav-list-item"><a href="/docs/velox-backend/troubleshooting/" class="nav-list-link">Troubleshooting</a></li><li class="nav-list-item"><a href="/docs/velox-backend/udf/" class="nav-list-link">Velox UDF</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Archives category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/" class="nav-list-link">Archives</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in v1.2.1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.2.1/" class="nav-list-link">v1.2.1</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Documentations(v1.2.1) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.2.1/docs/" class="nav-list-link">Documentations(v1.2.1)</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Getting-Started(v1.2.1) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.2.1/docs/getting-started/" class="nav-list-link">Getting-Started(v1.2.1)</a><ul class="nav-list"><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/velox-backend/" class="nav-list-link">Getting Start with Velox Backend(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/clickhouse-backend/" class="nav-list-link">Getting start with ClickHouse Backend(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/build-guide/" class="nav-list-link">Build Parameters for Velox Backend(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/s3/" class="nav-list-link">Using S3 with Gluten(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/gcs/" class="nav-list-link">Using GCS with Gluten(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/abfs/" class="nav-list-link">Using ABFS with Gluten(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/localcache/" class="nav-list-link">Velox Local Caching(v1.2.1)</a></li></ul></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/configuration/" class="nav-list-link">Configuration(v1.2.1)</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Developers(v1.2.1) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.2.1/docs/developers/" class="nav-list-link">Developers(v1.2.1)</a><ul class="nav-list"><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/how-to-use/" class="nav-list-link">How To Use Gluten(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/new-to/" class="nav-list-link">New To Gluten(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/microbenchmarks/" class="nav-list-link">Micro Benchmarks for Velox Backend(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/cpp-code-style/" class="nav-list-link">CPP Code Style(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/velox-function-dev/" class="nav-list-link">Velox Function Development(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/docker-ubuntu/" class="nav-list-link">Docker script for Ubuntu 22.04/20.04(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/docker-centos7/" class="nav-list-link">Docker script for CentOS 7(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/docker-centos8/" class="nav-list-link">Docker script for CentOS 8(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/substrait/" class="nav-list-link">Substrait Modifications(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/how-to-release/" class="nav-list-link">How To Release(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/developers/how-to-security-scan/" class="nav-list-link">How To Scan Security issues(v1.2.1)</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Velox Backend(v1.2.1) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.2.1/docs/velox-backend/" class="nav-list-link">Velox Backend(v1.2.1)</a><ul class="nav-list"><li class="nav-list-item"><a href="/archives/v1.2.1/docs/velox-backend/support/" class="nav-list-link">Supported Operators & Functions(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/velox-backend/limitations/" class="nav-list-link">Limitations(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/velox-backend/troubleshooting/" class="nav-list-link">Troubleshooting(v1.2.1)</a></li><li class="nav-list-item"><a href="/archives/v1.2.1/docs/velox-backend/udf/" class="nav-list-link">Velox UDF(v1.2.1)</a></li></ul></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in v1.1.1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.1.1/" class="nav-list-link">v1.1.1</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in v1.1.1/Documentation category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.1.1/docs/" class="nav-list-link">v1.1.1/Documentation</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in v1.1.1/Velox Backend category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.1.1/docs/velox/" class="nav-list-link">v1.1.1/Velox Backend</a><ul class="nav-list"><li class="nav-list-item"><a href="/archives/v1.1.1/docs/velox/getting-started/" class="nav-list-link">v1.1.1/Getting-Started with Velox Backend</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/docs/velox/build_parameters/" class="nav-list-link">v1.1.1/Build Parameters for Velox Backend</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/docs/velox/s3/" class="nav-list-link">v1.1.1/Using S3 with Gluten</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/docs/velox/gcs/" class="nav-list-link">v1.1.1/Using GCS with Gluten</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in v1.1.1/ClickHouse Backend category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.1.1/docs/clickhouse/" class="nav-list-link">v1.1.1/ClickHouse Backend</a><ul class="nav-list"><li class="nav-list-item"><a href="/archives/v1.1.1/docs/clickhouse/getting-started/" class="nav-list-link">v1.1.1/Getting Started with ClickHouse Backend</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in v1.1.1/Developers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/archives/v1.1.1/developers/" class="nav-list-link">v1.1.1/Developers</a><ul class="nav-list"><li class="nav-list-item"><a href="/archives/v1.1.1/developers/newto/" class="nav-list-link">v1.1.1/New To Gluten</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/howto/" class="nav-list-link">v1.1.1/How To Use Gluten</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/microbenchmark/" class="nav-list-link">v1.1.1/Micro Benchmarks for Velox Backend</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/cpp_code_style/" class="nav-list-link">v1.1.1/CPP Code Style</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/velox_function_development/" class="nav-list-link">v1.1.1/Velox Function Development</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/docker_ubuntu/" class="nav-list-link">v1.1.1/Docker script for Ubuntu 22.04/20.04</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/docker_centos8" class="nav-list-link">v1.1.1/Docker script for CentOS 8</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/docker_centos7/" class="nav-list-link">v1.1.1/Docker script for CentOS 7</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/substrait/" class="nav-list-link">v1.1.1/Substrait Modifications</a></li><li class="nav-list-item"><a href="/archives/v1.1.1/developers/howtorelease/" class="nav-list-link">v1.1.1/How To Release</a></li></ul></li></ul></li></ul></li><li class="nav-list-item"><a href="/downloads/" class="nav-list-link">Downloads</a></li><li class="nav-list-item"><a href="/blog/" class="nav-list-link">Blog</a></li><li class="nav-list-item"><a href="/references/" class="nav-list-link">Gluten References</a></li><li class="nav-list-item"><a href="/poweredby/" class="nav-list-link">Powered by Gluten</a></li><li class="nav-list-item"><a href="/contributing/" class="nav-list-link">Contributing to Gluten</a></li><li class="nav-list-item"><a href="/contact/" class="nav-list-link">Contact Us</a></li><li class="nav-list-item"><a href="/about/" class="nav-list-link">About</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Apache Gluten incubating" aria-label="Search Apache Gluten incubating" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <style> /* Style The Dropdown Button */ .dropbtn { background-color: #0000ff80; color: white; padding: 22px; width: 100%; font-size: 14px; border: none; cursor: pointer; } /* The container <div> - needed to position the dropdown content */ .dropdown { position: relative; display: inline-block; } /* Dropdown Content (Hidden by Default) */ .dropdown-content { display: none; position: absolute; background-color: #f9f9f9; min-width: 160px; box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2); z-index: 1; } /* Links inside the dropdown */ .dropdown-content a { color: black; padding: 12px 14px; text-decoration: none; display: block; } /* Change color of dropdown links on hover */ .dropdown-content a:hover {background-color: #f1f1f1} /* Show the dropdown menu on hover */ .dropdown:hover .dropdown-content { display: block; } /* Change the background color of the dropdown button when the dropdown content is shown */ .dropdown:hover .dropbtn { background-color: #0000ff; } </style> <!-- Collect the nav links, forms, and other content for toggling --> <div class="dropdown" id="apache-navbar" style="float:left;"> <button class="dropbtn">ASF</button> <div class="dropdown-content"> <a class="dropdown-item" href="https://www.apache.org/">Foundation</a> <a class="dropdown-item" href="https://www.apache.org/events/current-event.html">Event</a> <a class="dropdown-item" href="https://www.apache.org/licenses/">License</a> <a class="dropdown-item" href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a> <a class="dropdown-item" href="https://www.apache.org/security/">Security</a> <a class="dropdown-item" href="https://privacy.apache.org/policies/privacy-policy-public.html">Privacy</a> <a class="dropdown-item" href="https://www.apache.org/foundation/thanks.html">Thanks</a> </div> </div><!-- /.navbar-collapse --> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="//github.com/apache/incubator-gluten" class="site-button" target="_blank" rel="noopener noreferrer" > Apache Gluten Github </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/archives/">Archives</a></li> <li class="breadcrumb-nav-list-item"><a href="/archives/v1.2.1/">v1.2.1</a></li> <li class="breadcrumb-nav-list-item"><a href="/archives/v1.2.1/docs/">Documentations(v1.2.1)</a></li> <li class="breadcrumb-nav-list-item"><a href="/archives/v1.2.1/docs/getting-started/">Getting-Started(v1.2.1)</a></li> <li class="breadcrumb-nav-list-item"><span>Getting start with ClickHouse Backend(v1.2.1)</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h2 id="clickhouse-backend"> <a href="#clickhouse-backend" class="anchor-heading" aria-labelledby="clickhouse-backend"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ClickHouse Backend </h2> <p>ClickHouse is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP), which supports best in the industry query performance, while significantly reducing storage requirements through its innovative use of columnar storage and compression. We port ClickHouse ( based on version <strong>23.1</strong> ) as a library, called ‘libch.so’, and Gluten loads this library through JNI as the native engine. In this way, we don’t need to deploy a standalone ClickHouse Cluster, Spark uses Gluten as SparkPlugin to read and write ClickHouse MergeTree data.</p> <h3 id="architecture"> <a href="#architecture" class="anchor-heading" aria-labelledby="architecture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Architecture </h3> <p>The architecture of the ClickHouse backend is shown below:</p> <p><img src="/assets/images/ClickHouse/ClickHouse-Backend-Architecture.png" alt="ClickHouse-Backend-Architecture" /></p> <ol> <li>On Spark driver, Spark uses Gluten SparkPlugin to transform the physical plan to the Substrait plan, and then pass the Substrait plan to ClickHouse backend through JNI call on executors.</li> <li>Based on Spark DataSource V2 interface, implementing a ClickHouse Catalog to support operating the ClickHouse tables, and then using Delta to save some metadata about ClickHouse like the MergeTree parts information, and also provide ACID transactions.</li> <li>When querying from a ClickHouse table, it will fetch MergeTree parts information from Delta metadata and assign these parts into Spark partitions according to some strategies.</li> <li>When writing data into a ClickHouse table, it will use ClickHouse library to write MergeTree parts data and collect these MergeTree parts information after writing successfully, and then save these MergeTree parts information into Delta metadata. ( <strong>The feature of writing MergeTree parts is coming soon.</strong> )</li> <li>On Spark executors, each executor will load the ‘libch.so’ through JNI when starting, and then call the operators according to the Substrait plan which is passed from Spark Driver, like reading data from the MergeTree parts, writing the MergeTree parts, filtering data, aggregating data and so on.</li> <li>Currently, the ClickHouse backend only supports reading the MergeTree parts from local storage, it needs to use a high-performance shared file system to share a root bucket on every node of the cluster from the object storage, like JuiceFS.</li> </ol> <h3 id="development-environment-setup"> <a href="#development-environment-setup" class="anchor-heading" aria-labelledby="development-environment-setup"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Development environment setup </h3> <p>In general, we use IDEA for Gluten development and CLion for ClickHouse backend development on <strong>Ubuntu 20</strong>.</p> <h4 id="prerequisites"> <a href="#prerequisites" class="anchor-heading" aria-labelledby="prerequisites"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Prerequisites </h4> <p>Install the software required for compilation, run <code class="language-plaintext highlighter-rouge">sudo ./ep/build-clickhouse/src/install_ubuntu.sh</code>. Under the hood, it will install the following software:</p> <ul> <li>Clang 16.0</li> <li>cmake 3.20 or higher version</li> <li>ninja-build 1.8.2</li> </ul> <p>You can also refer to <a href="https://clickhouse.com/docs/en/development/build/">How-to-Build-ClickHouse-on-Linux</a>. You need to install the following software manually:</p> <ul> <li>Java 8</li> <li>Maven 3.6.3 or higher version</li> <li>Spark 3.2.2 or Spark 3.3.1</li> </ul> <p>Then, get Gluten code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    git clone https://github.com/apache/incubator-gluten.git
</code></pre></div></div> <h4 id="setup-clickhouse-backend-development-environment"> <a href="#setup-clickhouse-backend-development-environment" class="anchor-heading" aria-labelledby="setup-clickhouse-backend-development-environment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Setup ClickHouse backend development environment </h4> <p>If you don’t care about development environment, you can skip this part.</p> <p>Otherwise, do:</p> <ol> <li>clone Kyligence/ClickHouse repo <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">cd</span> /to/some/place/
 git clone <span class="nt">--recursive</span> <span class="nt">--shallow-submodules</span> <span class="nt">-b</span> clickhouse_backend https://github.com/Kyligence/ClickHouse.git
</code></pre></div> </div> </li> <li> <p>Configure cpp-ch ${GLUTEN_SOURCE}/cpp-ch can be treated as an add-on of Kyligence/Clickhouse</p> <p>First, initialize some configuration for this add-on:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">export </span><span class="nv">GLUTEN_SOURCE</span><span class="o">=</span>/path/to/gluten
 <span class="nb">export </span><span class="nv">CH_SOURCE_DIR</span><span class="o">=</span>/path/to/ClickHouse
 cmake <span class="nt">-G</span> Ninja <span class="nt">-S</span> <span class="k">${</span><span class="nv">GLUTEN_SOURCE</span><span class="k">}</span>/cpp-ch <span class="nt">-B</span> <span class="k">${</span><span class="nv">GLUTEN_SOURCE</span><span class="k">}</span>/cpp-ch/build_ch <span class="nt">-DCH_SOURCE_DIR</span><span class="o">=</span><span class="k">${</span><span class="nv">CH_SOURCE_DIR</span><span class="k">}</span> <span class="s2">"-DCMAKE_C_COMPILER=</span><span class="si">$(</span><span class="nb">command</span> <span class="nt">-v</span> clang-16<span class="si">)</span><span class="s2">"</span> <span class="s2">"-DCMAKE_CXX_COMPILER=</span><span class="si">$(</span><span class="nb">command</span> <span class="nt">-v</span> clang++-16<span class="si">)</span><span class="s2">"</span> <span class="s2">"-DCMAKE_BUILD_TYPE=RelWithDebInfo"</span>
</code></pre></div> </div> <p>Next, you need to compile Kyligence/Clickhouse. There are two options:</p> </li> <li> <p>(Option 1) Use CLion</p> <ul> <li>Open ClickHouse repo</li> <li> <p>Choose File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Toolchains, and then choose Bundled CMake, clang-16 as C Compiler, clang++-16 as C++ Compiler:</p> <p><img src="/assets/images/ClickHouse/CLion-Configuration-1.png" alt="ClickHouse-CLion-Toolchains" /></p> </li> <li> <p>Choose File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake:</p> <p><img src="/assets/images/ClickHouse/CLion-Configuration-2.png" alt="ClickHouse-CLion-Toolchains" /></p> <p>And then add these options into CMake options:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nt">-DENABLE_PROTOBUF</span><span class="o">=</span>ON <span class="nt">-DENABLE_TESTS</span><span class="o">=</span>OFF <span class="nt">-DENABLE_JEMALLOC</span><span class="o">=</span>ON <span class="nt">-DENABLE_MULTITARGET_CODE</span><span class="o">=</span>ON <span class="nt">-DENABLE_EXTERN_LOCAL_ENGINE</span><span class="o">=</span>ON
</code></pre></div> </div> </li> <li> <p>Build ‘ch’ target on ClickHouse Project with Debug mode or Release mode:</p> <p><img src="/assets/images/ClickHouse/CLion-Configuration-3.png" alt="ClickHouse-CLion-Toolchains" /></p> <p>If it builds with Release mode successfully, there is a library file called ‘libch.so’ in path ‘${CH_SOURCE_DIR}/cmake-build-release/utils/extern-local-engine/’.</p> <p>If it builds with Debug mode successfully, there is a library file called ‘libchd.so’ in path ‘${CH_SOURCE_DIR}/cmake-build-debug/utils/extern-local-engine/’.</p> </li> </ul> </li> <li>(Option 2) Use command line <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code> cmake <span class="nt">--build</span> <span class="k">${</span><span class="nv">GLUTEN_SOURCE</span><span class="k">}</span>/cpp-ch/build_ch <span class="nt">--target</span> build_ch
</code></pre></div> </div> <p>If it builds successfully, there is a library file called ‘libch.so’ in path ‘${GLUTEN_SOURCE}/cpp-ch/build/utils/extern-local-engine/’.</p> </li> </ol> <h3 id="directly-compile-clickhouse-backend"> <a href="#directly-compile-clickhouse-backend" class="anchor-heading" aria-labelledby="directly-compile-clickhouse-backend"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Directly Compile ClickHouse backend </h3> <p>In case you don’t want a develop environment, you can use the following command to compile ClickHouse backend directly:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/apache/incubator-gluten.git
<span class="nb">cd </span>incubator-gluten
bash ./ep/build-clickhouse/src/build_clickhouse.sh
</code></pre></div></div> <p>This will download Clickhouse for you and build everything. The target file is <code class="language-plaintext highlighter-rouge">/path/to/gluten/cpp-ch/build/utils/extern-local-engine/libch.so</code>.</p> <h3 id="compile-gluten"> <a href="#compile-gluten" class="anchor-heading" aria-labelledby="compile-gluten"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Compile Gluten </h3> <p>The prerequisites are the same as the one mentioned above. Compile Gluten with ClickHouse backend through maven:</p> <ul> <li>for Spark 3.2.2<span id="deploy-spark-322"></span></li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    git clone https://github.com/apache/incubator-gluten.git
    <span class="nb">cd </span>incubator-gluten/
    <span class="nb">export </span><span class="nv">MAVEN_OPTS</span><span class="o">=</span><span class="s2">"-Xmx8g -XX:ReservedCodeCacheSize=2g"</span>
    mvn clean <span class="nb">install</span> <span class="nt">-Pbackends-clickhouse</span> <span class="nt">-Phadoop-2</span>.7.4 <span class="nt">-Pspark-3</span>.2 <span class="nt">-Dhadoop</span>.version<span class="o">=</span>2.8.5 <span class="nt">-DskipTests</span> <span class="nt">-Dcheckstyle</span>.skip
    <span class="nb">ls</span> <span class="nt">-al</span> backends-clickhouse/target/gluten-XXXXX-spark-3.2-jar-with-dependencies.jar
</code></pre></div></div> <ul> <li>for Spark 3.3.1</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    git clone https://github.com/apache/incubator-gluten.git
    <span class="nb">cd </span>incubator-gluten/
    <span class="nb">export </span><span class="nv">MAVEN_OPTS</span><span class="o">=</span><span class="s2">"-Xmx8g -XX:ReservedCodeCacheSize=2g"</span>
    mvn clean <span class="nb">install</span> <span class="nt">-Pbackends-clickhouse</span> <span class="nt">-Phadoop-2</span>.7.4 <span class="nt">-Pspark-3</span>.3 <span class="nt">-Dhadoop</span>.version<span class="o">=</span>2.8.5 <span class="nt">-DskipTests</span> <span class="nt">-Dcheckstyle</span>.skip
    <span class="nb">ls</span> <span class="nt">-al</span> backends-clickhouse/target/gluten-XXXXX-spark-3.3-jar-with-dependencies.jar
</code></pre></div></div> <h3 id="gluten-in-local-spark-thrift-server"> <a href="#gluten-in-local-spark-thrift-server" class="anchor-heading" aria-labelledby="gluten-in-local-spark-thrift-server"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Gluten in local Spark Thrift Server </h3> <h4 id="prepare-working-directory"> <a href="#prepare-working-directory" class="anchor-heading" aria-labelledby="prepare-working-directory"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Prepare working directory </h4> <ul> <li>for Spark 3.2.2</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar </span>zxf spark-3.2.2-bin-hadoop2.7.tgz
<span class="nb">cd </span>spark-3.2.2-bin-hadoop2.7
<span class="nb">rm</span> <span class="nt">-f</span> jars/protobuf-java-2.5.0.jar
<span class="c">#download protobuf-java-3.23.4.jar, delta-core_2.12-2.0.1.jar and delta-storage-2.0.1.jar</span>
wget https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.23.4/protobuf-java-3.23.4.jar <span class="nt">-P</span> ./jars
wget https://repo1.maven.org/maven2/io/delta/delta-core_2.12/2.0.1/delta-core_2.12-2.0.1.jar <span class="nt">-P</span> ./jars
wget https://repo1.maven.org/maven2/io/delta/delta-storage/2.0.1/delta-storage-2.0.1.jar <span class="nt">-P</span> ./jars
<span class="nb">cp </span>gluten-XXXXX-spark-3.2-jar-with-dependencies.jar jars/
</code></pre></div></div> <ul> <li>for Spark 3.3.1</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar </span>zxf spark-3.3.1-bin-hadoop2.7.tgz
<span class="nb">cd </span>spark-3.3.1-bin-hadoop2.7
<span class="nb">rm</span> <span class="nt">-f</span> jars/protobuf-java-2.5.0.jar
<span class="c">#download protobuf-java-3.23.4.jar, delta-core_2.12-2.2.0.jar and delta-storage-2.2.0.jar</span>
wget https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.23.4/protobuf-java-3.23.4.jar <span class="nt">-P</span> ./jars
wget https://repo1.maven.org/maven2/io/delta/delta-core_2.12/2.2.0/delta-core_2.12-2.2.0.jar <span class="nt">-P</span> ./jars
wget https://repo1.maven.org/maven2/io/delta/delta-storage/2.2.0/delta-storage-2.2.0.jar <span class="nt">-P</span> ./jars
<span class="nb">cp </span>gluten-XXXXX-spark-3.3-jar-with-dependencies.jar jars/
</code></pre></div></div> <h4 id="query-local-data"> <a href="#query-local-data" class="anchor-heading" aria-labelledby="query-local-data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Query local data </h4> <h5 id="start-spark-thriftserver-on-local"> <a href="#start-spark-thriftserver-on-local" class="anchor-heading" aria-labelledby="start-spark-thriftserver-on-local"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Start Spark Thriftserver on local </h5> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>spark-3.2.2-bin-hadoop2.7
./sbin/start-thriftserver.sh <span class="se">\</span>
  <span class="nt">--master</span> <span class="nb">local</span><span class="o">[</span>3] <span class="se">\</span>
  <span class="nt">--driver-memory</span> 10g <span class="se">\</span>
  <span class="nt">--conf</span> spark.serializer<span class="o">=</span>org.apache.spark.serializer.JavaSerializer <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.sources.ignoreDataLocality<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.default.parallelism<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.shuffle.partitions<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.minPartitionNum<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.maxPartitionBytes<span class="o">=</span>1073741824 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.adaptive.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait.node<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait.process<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.columnVector.offheap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.size<span class="o">=</span>6442450944 <span class="se">\</span>
  <span class="nt">--conf</span> spark.plugins<span class="o">=</span>org.apache.gluten.GlutenPlugin <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.columnarToRow<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.executorEnv.LD_PRELOAD<span class="o">=</span>/path_to_clickhouse_library/libch.so<span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.libpath<span class="o">=</span>/path_to_clickhouse_library/libch.so <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.iterator<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.loadarrow<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.hashagg.enablefinal<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.enable.native.validation<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.io.compression.codec<span class="o">=</span>snappy <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.forceShuffledHashJoin<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.catalog.spark_catalog<span class="o">=</span>org.apache.spark.sql.execution.datasources.v2.clickhouse.ClickHouseSparkCatalog <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.maxSnapshotLineageLength<span class="o">=</span>20 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.snapshotPartitions<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.properties.defaults.checkpointInterval<span class="o">=</span>5 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.stalenessLimit<span class="o">=</span>3600000

<span class="c">#connect to Spark Thriftserver by beeline</span>
bin/beeline <span class="nt">-u</span> jdbc:hive2://localhost:10000/ <span class="nt">-n</span> root
</code></pre></div></div> <h5 id="query-local-mergetree-files"> <a href="#query-local-mergetree-files" class="anchor-heading" aria-labelledby="query-local-mergetree-files"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Query local MergeTree files </h5> <ul> <li>Prepare data<span id="data-preparation"></span></li> </ul> <p>Currently, the feature of writing ClickHouse MergeTree parts by Spark is developing, so you need to use command ‘clickhouse-local’ to generate MergeTree parts data manually. We provide a python script to call the command ‘clickhouse-local’ to convert parquet data to MergeTree parts:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c">#install ClickHouse community version</span>
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> apt-transport-https ca-certificates dirmngr
<span class="nb">sudo </span>apt-key adv <span class="nt">--keyserver</span> hkp://keyserver.ubuntu.com:80 <span class="nt">--recv</span> 8919F6BD2B48D754
<span class="nb">echo</span> <span class="s2">"deb https://packages.clickhouse.com/deb stable main"</span> | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/clickhouse.list
<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt <span class="nb">install</span> <span class="nt">-y</span> <span class="nt">--allow-downgrades</span> clickhouse-server<span class="o">=</span>22.5.1.2079 clickhouse-client<span class="o">=</span>22.5.1.2079 clickhouse-common-static<span class="o">=</span>22.5.1.2079

<span class="c">#generate MergeTree parts</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /path_clickhouse_database/table_path/
python3 /path_to_clickhouse_backend_src/utils/local-engine/tool/parquet_to_mergetree.py <span class="nt">--path</span><span class="o">=</span>/tmp <span class="nt">--source</span><span class="o">=</span>/path_to_parquet_data/tpch-data-sf100/lineitem <span class="nt">--dst</span><span class="o">=</span>/path_clickhouse_database/table_path/lineitem
</code></pre></div></div> <p><strong>This python script will convert one parquet data file to one MergeTree parts.</strong></p> <ul> <li>Create a TPC-H lineitem table using ClickHouse DataSource</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">lineitem</span><span class="p">;</span>
    <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">lineitem</span> <span class="p">(</span>
     <span class="n">l_orderkey</span>      <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_partkey</span>       <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_suppkey</span>       <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_linenumber</span>    <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_quantity</span>      <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_extendedprice</span> <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_discount</span>      <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_tax</span>           <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_returnflag</span>    <span class="n">string</span><span class="p">,</span>
     <span class="n">l_linestatus</span>    <span class="n">string</span><span class="p">,</span>
     <span class="n">l_shipdate</span>      <span class="nb">date</span><span class="p">,</span>
     <span class="n">l_commitdate</span>    <span class="nb">date</span><span class="p">,</span>
     <span class="n">l_receiptdate</span>   <span class="nb">date</span><span class="p">,</span>
     <span class="n">l_shipinstruct</span>  <span class="n">string</span><span class="p">,</span>
     <span class="n">l_shipmode</span>      <span class="n">string</span><span class="p">,</span>
     <span class="n">l_comment</span>       <span class="n">string</span><span class="p">)</span>
     <span class="k">USING</span> <span class="n">clickhouse</span>
     <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s1">'MergeTree'</span>
                    <span class="p">)</span>
     <span class="k">LOCATION</span> <span class="s1">'/path_clickhouse_database/table_path/lineitem'</span><span class="p">;</span>
</code></pre></div></div> <ul> <li>TPC-H Q6 test</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="k">sum</span><span class="p">(</span><span class="n">l_extendedprice</span> <span class="o">*</span> <span class="n">l_discount</span><span class="p">)</span> <span class="k">AS</span> <span class="n">revenue</span>
    <span class="k">FROM</span>
        <span class="n">lineitem</span>
    <span class="k">WHERE</span>
        <span class="n">l_shipdate</span> <span class="o">&gt;=</span> <span class="nb">date</span><span class="s1">'1994-01-01'</span>
        <span class="k">AND</span> <span class="n">l_shipdate</span> <span class="o">&lt;</span> <span class="nb">date</span><span class="s1">'1994-01-01'</span> <span class="o">+</span> <span class="n">interval</span> <span class="mi">1</span> <span class="nb">year</span>
        <span class="k">AND</span> <span class="n">l_discount</span> <span class="k">BETWEEN</span> <span class="mi">0</span><span class="p">.</span><span class="mi">06</span> <span class="o">-</span> <span class="mi">0</span><span class="p">.</span><span class="mi">01</span> <span class="k">AND</span> <span class="mi">0</span><span class="p">.</span><span class="mi">06</span> <span class="o">+</span> <span class="mi">0</span><span class="p">.</span><span class="mi">01</span>
        <span class="k">AND</span> <span class="n">l_quantity</span> <span class="o">&lt;</span> <span class="mi">24</span><span class="p">;</span>
</code></pre></div></div> <ul> <li> <p>Result</p> <p>The DAG is shown on Spark UI as below:</p> <p><img src="/assets/images/ClickHouse/Gluten-ClickHouse-Backend-Q6-DAG.png" alt="ClickHouse-CLion-Toolchains" /></p> </li> </ul> <h5 id="query-local-parquet-files"> <a href="#query-local-parquet-files" class="anchor-heading" aria-labelledby="query-local-parquet-files"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Query local Parquet files </h5> <p>You can query local parquet files directly.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- query on a single file</span>
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">parquet</span><span class="p">.</span><span class="nv">`/your_data_root_dir/1.parquet`</span><span class="p">;</span>

<span class="c1">-- query on a directly which has multiple files</span>
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">parquet</span><span class="p">.</span><span class="nv">`/your_data_roo_dir/`</span><span class="p">;</span>
</code></pre></div></div> <p>You can also create a TEMPORARY VIEW for parquet files.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">or</span> <span class="k">replace</span> <span class="k">temporary</span> <span class="k">view</span> <span class="n">your_table_name</span>
<span class="k">using</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">spark</span><span class="p">.</span><span class="k">sql</span><span class="p">.</span><span class="n">parquet</span>
<span class="k">options</span><span class="p">(</span>
    <span class="n">path</span> <span class="nv">"/your_data_root_dir/"</span>
<span class="p">)</span>
</code></pre></div></div> <h5 id="query-parquet-files-in-s3"> <a href="#query-parquet-files-in-s3" class="anchor-heading" aria-labelledby="query-parquet-files-in-s3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Query Parquet files in S3 </h5> <p>If you have parquet files in S3(either AWS S3 or S3 compatible storages like MINIO), you can query them directly. You need to add these additional configs to spark:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nt">--config</span> spark.hadoop.fs.s3a.endpoint<span class="o">=</span>S3_ENDPOINT
  <span class="nt">--config</span> spark.hadoop.fs.s3a.path.style.access<span class="o">=</span><span class="nb">true</span>
  <span class="nt">--config</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span>YOUR_ACCESS_KEY
  <span class="nt">--config</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span>YOUR_SECRET_KEY
</code></pre></div></div> <p>where S3_ENDPOINT must follow the format of <code class="language-plaintext highlighter-rouge">https://s3.region-code.amazonaws.com</code>, e.g. <code class="language-plaintext highlighter-rouge">https://s3.us-east-1.amazonaws.com</code> (or `http://hostname:39090 for MINIO)</p> <p>When you query the parquet files in S3, you need to add the prefix <code class="language-plaintext highlighter-rouge">s3a://</code> to the path, e.g. <code class="language-plaintext highlighter-rouge">s3a://your_bucket_name/path_to_your_parquet</code>.</p> <p>Additionally, you can add these configs to enable local caching of S3 data. Each spark executor will have its own cache. Cache stealing between executors is not supported yet.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nt">--config</span> spark.gluten.sql.columnar.backend.ch.runtime_config.s3.local_cache.enabled<span class="o">=</span><span class="nb">true</span>
  <span class="nt">--config</span> spark.gluten.sql.columnar.backend.ch.runtime_config.s3.local_cache.cache_path<span class="o">=</span>/executor_local_folder_for_cache
</code></pre></div></div> <h5 id="use-beeline-to-execute-queries"> <a href="#use-beeline-to-execute-queries" class="anchor-heading" aria-labelledby="use-beeline-to-execute-queries"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Use beeline to execute queries </h5> <p>After start a spark thriftserver, we can use the beeline to connect to this server.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># run a file</span>
/path_to_spark/bin/beeline <span class="nt">-u</span> jdbc:hive2://localhost:10000 <span class="nt">-f</span> &lt;your_sql_file&gt;

<span class="c"># run a query</span>
/path_to_spark/bin/beeline <span class="nt">-u</span> jdbc:hive2://localhost:10000 <span class="nt">-e</span> <span class="s1">'&lt;your_sql&gt;'</span>

<span class="c"># enter a interactive mode</span>
/path_to_spark/bin/beeline <span class="nt">-u</span> jdbc:hive2://localhost:10000
</code></pre></div></div> <h4 id="query-hive-tables-in-hdfs"> <a href="#query-hive-tables-in-hdfs" class="anchor-heading" aria-labelledby="query-hive-tables-in-hdfs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Query Hive tables in HDFS </h4> <p>Suppose that you have set up hive and hdfs, you can query the data on hive directly.</p> <ul> <li>Copy <code class="language-plaintext highlighter-rouge">hive-site.xml</code> into <code class="language-plaintext highlighter-rouge">/path_to_spark/conf/</code></li> <li>Copy <code class="language-plaintext highlighter-rouge">hdfs-site.xml</code> into <code class="language-plaintext highlighter-rouge">/path_to_spark/conf/</code>, and edit <code class="language-plaintext highlighter-rouge">spark-env.sh</code></li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># add this line into spark-env.sh</span>
<span class="nb">export </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span>/path_to_spark/conf
</code></pre></div></div> <ul> <li>Start spark thriftserver with hdfs configurations</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">hdfs_conf_file</span><span class="o">=</span>/your_local_path/hdfs-site.xml

<span class="nb">cd </span>spark-3.2.2-bin-hadoop2.7
<span class="c"># add a new option: spark.gluten.sql.columnar.backend.ch.runtime_config.hdfs.libhdfs3_conf</span>
./sbin/start-thriftserver.sh <span class="se">\</span>
  <span class="nt">--master</span> <span class="nb">local</span><span class="o">[</span>3] <span class="se">\</span>
  <span class="nt">--files</span> <span class="nv">$hdfs_conf_file</span> <span class="se">\</span>
  <span class="nt">--driver-memory</span> 10g <span class="se">\</span>
  <span class="nt">--conf</span> spark.serializer<span class="o">=</span>org.apache.spark.serializer.JavaSerializer <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.sources.ignoreDataLocality<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.default.parallelism<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.shuffle.partitions<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.minPartitionNum<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.maxPartitionBytes<span class="o">=</span>1073741824 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait.node<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait.process<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.columnVector.offheap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.size<span class="o">=</span>6442450944 <span class="se">\</span>
  <span class="nt">--conf</span> spark.plugins<span class="o">=</span>org.apache.gluten.GlutenPlugin <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.columnarToRow<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.executorEnv.LD_PRELOAD<span class="o">=</span>/path_to_clickhouse_library/libch.so<span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.libpath<span class="o">=</span>/path_to_clickhouse_library/libch.so <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.iterator<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.loadarrow<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.hashagg.enablefinal<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.enable.native.validation<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.io.compression.codec<span class="o">=</span>snappy <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.forceShuffledHashJoin<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.catalog.spark_catalog<span class="o">=</span>org.apache.spark.sql.execution.datasources.v2.clickhouse.ClickHouseSparkCatalog <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.maxSnapshotLineageLength<span class="o">=</span>20 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.snapshotPartitions<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.properties.defaults.checkpointInterval<span class="o">=</span>5 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.stalenessLimit<span class="o">=</span>3600000 <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.backend.ch.runtime_config.hdfs.libhdfs3_conf<span class="o">=</span>./hdfs-site.xml
</code></pre></div></div> <p>For example, you have a table <code class="language-plaintext highlighter-rouge">demo_database</code>.<code class="language-plaintext highlighter-rouge">demo_table</code> on the hive, you can run queries as below.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">demo_database</span><span class="p">.</span><span class="n">demo_talbe</span><span class="p">;</span>
</code></pre></div></div> <h3 id="gluten-in-yarn-cluster"> <a href="#gluten-in-yarn-cluster" class="anchor-heading" aria-labelledby="gluten-in-yarn-cluster"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Gluten in YARN cluster </h3> <p>We can to run a Spark SQL task by gluten on a yarn cluster as following</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="c"># The file contains the sql you want to run</span>
<span class="nv">sql_file</span><span class="o">=</span>/path/to/spark/sql/file

<span class="nb">export </span><span class="nv">SPARK_HOME</span><span class="o">=</span>/path/to/spark/home
<span class="nv">spark_cmd</span><span class="o">=</span><span class="nv">$SPARK_HOME</span>/bin/spark-sql

<span class="c"># Define the path to libch.so</span>
<span class="nv">ch_lib</span><span class="o">=</span>/path/to/libch.so
<span class="nb">export </span><span class="nv">LD_PRELOAD</span><span class="o">=</span><span class="nv">$ch_lib</span>

<span class="c"># copy gluten jar file to $SPARK_HOME/jar</span>
<span class="nv">gluten_jar</span><span class="o">=</span>/path/to/gluten/jar/file
<span class="nb">cp</span> <span class="nv">$gluten_jar</span> <span class="nv">$SPARK_HOME</span>/jar

<span class="nv">batchsize</span><span class="o">=</span>20480
<span class="nv">hdfs_conf</span><span class="o">=</span>/path/to/hdfs-site.xml

<span class="nv">$spark_cmd</span> <span class="se">\</span>
  <span class="nt">--name</span> gluten_on_yarn
  <span class="nt">--master</span> yarn <span class="se">\</span>
  <span class="nt">--deploy-mode</span> client <span class="se">\</span>
  <span class="nt">--files</span> <span class="nv">$ch_lib</span> <span class="se">\</span>
  <span class="nt">--executor-cores</span> 1 <span class="se">\</span>
  <span class="nt">--num-executors</span> 2 <span class="se">\</span>
  <span class="nt">--executor-memory</span> 10g <span class="se">\</span>
  <span class="nt">--conf</span> spark.default.parallelism<span class="o">=</span>4 <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.size<span class="o">=</span>7g <span class="se">\</span>
  <span class="nt">--conf</span> spark.driver.maxResultSize<span class="o">=</span>2g <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.autoBroadcastJoinThreshold<span class="o">=</span><span class="nt">-1</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.parquet.columnarReaderBatchSize<span class="o">=</span><span class="k">${</span><span class="nv">batchsize</span><span class="k">}</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.inMemoryColumnarStorage.batchSize<span class="o">=</span><span class="k">${</span><span class="nv">batchsize</span><span class="k">}</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.execution.arrow.maxRecordsPerBatch<span class="o">=</span><span class="k">${</span><span class="nv">batchsize</span><span class="k">}</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.broadcastTimeout<span class="o">=</span>4800 <span class="se">\</span>
  <span class="nt">--conf</span> spark.task.maxFailures<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.excludeOnFailure.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.driver.maxResultSize<span class="o">=</span>4g <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.adaptive.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.dynamicAllocation.executorIdleTimeout<span class="o">=</span>0s <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.shuffle.partitions<span class="o">=</span>112 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.sources.useV1SourceList<span class="o">=</span>avro <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.maxPartitionBytes<span class="o">=</span>1073741824 <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.columnartorow<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.loadnative<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.libpath<span class="o">=</span><span class="nv">$ch_lib</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.iterator<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.loadarrow<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.hashagg.enablefinal<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.enable.native.validation<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.forceShuffledHashJoin<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.backend.ch.runtime_config.hdfs.libhdfs3_conf<span class="o">=</span><span class="nv">$hdfs_conf</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.backend.ch.runtime_config.logger.level<span class="o">=</span>debug <span class="se">\</span>
  <span class="nt">--conf</span> spark.plugins<span class="o">=</span>org.apache.gluten.GlutenPlugin <span class="se">\</span>
  <span class="nt">--conf</span> spark.executorEnv.LD_PRELOAD<span class="o">=</span><span class="nv">$LD_PRELOAD</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.hadoop.input.connect.timeout<span class="o">=</span>600000 <span class="se">\</span>
  <span class="nt">--conf</span> spark.hadoop.input.read.timeout<span class="o">=</span>600000 <span class="se">\</span>
  <span class="nt">--conf</span> spark.hadoop.input.write.timeout<span class="o">=</span>600000 <span class="se">\</span>
  <span class="nt">--conf</span> spark.hadoop.dfs.client.log.severity<span class="o">=</span><span class="s2">"DEBUG2"</span> <span class="se">\</span>
  <span class="nt">--files</span> <span class="nv">$ch_lib</span> <span class="se">\</span>
  <span class="nt">-f</span> <span class="nv">$sql_file</span>
</code></pre></div></div> <p>We also can use <code class="language-plaintext highlighter-rouge">spark-submit</code> to run a task.</p> <h3 id="benchmark-with-tpc-h-100-q6-on-gluten-with-clickhouse-backend"> <a href="#benchmark-with-tpc-h-100-q6-on-gluten-with-clickhouse-backend" class="anchor-heading" aria-labelledby="benchmark-with-tpc-h-100-q6-on-gluten-with-clickhouse-backend"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Benchmark with TPC-H 100 Q6 on Gluten with ClickHouse backend </h3> <p>This benchmark is tested on AWS EC2 cluster, there are 7 EC2 instances:</p> <div class="table-wrapper"><table> <thead> <tr> <th>Node Role</th> <th>EC2 Type</th> <th>Instances Count</th> <th>Resources</th> <th>AMI</th> </tr> </thead> <tbody> <tr> <td>Master</td> <td>m5.4xlarge</td> <td>1</td> <td>16 cores 64G memory per node</td> <td>ubuntu-focal-20.04</td> </tr> <tr> <td>Worker</td> <td>m5.4xlarge</td> <td>1</td> <td>16 cores 64G memory per node</td> <td>ubuntu-focal-20.04</td> </tr> </tbody> </table></div> <h4 id="deploy-on-cloud"> <a href="#deploy-on-cloud" class="anchor-heading" aria-labelledby="deploy-on-cloud"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Deploy on Cloud </h4> <ul> <li> <p>Tested on Spark Standalone cluster, its resources are shown below:</p> <div class="table-wrapper"><table> <thead> <tr> <th> </th> <th>CPU cores</th> <th>Memory</th> <th>Instances Count</th> </tr> </thead> <tbody> <tr> <td>Spark Worker</td> <td>15</td> <td>60G</td> <td>6</td> </tr> </tbody> </table></div> </li> <li> <p>Prepare jars</p> <p>Refer to <a href="#deploy-spark-322">Deploy Spark 3.2.2</a></p> </li> <li> <p>Deploy gluten-core-XXXXX-jar-with-dependencies.jar</p> </li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c">#deploy 'gluten-core-XXXXX-jar-with-dependencies.jar' to every node, and then</span>
    <span class="nb">cp </span>gluten-core-XXXXX-jar-with-dependencies.jar /path_to_spark/jars/
</code></pre></div></div> <ul> <li> <p>Deploy ClickHouse library</p> <p>Deploy ClickHouse library ‘libch.so’ to every worker node.</p> </li> </ul> <h5 id="deploy-juicefs"> <a href="#deploy-juicefs" class="anchor-heading" aria-labelledby="deploy-juicefs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Deploy JuiceFS </h5> <ul> <li>JuiceFS uses Redis to save metadata, install redis firstly:</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    wget https://download.redis.io/releases/redis-6.0.14.tar.gz
    <span class="nb">sudo </span>apt <span class="nb">install </span>build-essential
    <span class="nb">tar</span> <span class="nt">-zxvf</span> redis-6.0.14.tar.gz
    <span class="nb">cd </span>redis-6.0.14
    make
    make <span class="nb">install </span><span class="nv">PREFIX</span><span class="o">=</span>/home/ubuntu/redis6
    <span class="nb">cd</span> ..
    <span class="nb">rm</span> <span class="nt">-rf</span> redis-6.0.14

    <span class="c">#start redis server</span>
    /home/ubuntu/redis6/bin/redis-server /home/ubuntu/redis6/redis.conf

</code></pre></div></div> <ul> <li> <p>Use JuiceFS to format a S3 bucket and mount a volumn on every node</p> <p>Please refer to <a href="https://juicefs.com/docs/community/command_reference">The-JuiceFS-Command-Reference</a></p> </li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    wget https://github.com/juicedata/juicefs/releases/download/v0.17.5/juicefs-0.17.5-linux-amd64.tar.gz
    <span class="nb">tar</span> <span class="nt">-zxvf</span> juicefs-0.17.5-linux-amd64.tar.gz

    ./juicefs format <span class="nt">--block-size</span> 4096 <span class="nt">--storage</span> s3 <span class="nt">--bucket</span> https://s3.cn-northwest-1.amazonaws.com.cn/s3-gluten-tpch100/ <span class="nt">--access-key</span> <span class="s2">"XXXXXXXX"</span> <span class="nt">--secret-key</span> <span class="s2">"XXXXXXXX"</span> redis://:123456@master-ip:6379/1 gluten-tables

    <span class="c">#mount a volumn on every node</span>
    ./juicefs mount <span class="nt">-d</span> <span class="nt">--no-usage-report</span> <span class="nt">--no-syslog</span> <span class="nt">--attr-cache</span> 7200 <span class="nt">--entry-cache</span> 7200 <span class="nt">--dir-entry-cache</span> 7200 <span class="nt">--buffer-size</span> 500 <span class="nt">--prefetch</span> 1 <span class="nt">--open-cache</span> 86400 <span class="nt">--log</span> /home/ubuntu/juicefs-logs/mount1.log <span class="nt">--cache-dir</span> /home/ubuntu/juicefs-cache/ <span class="nt">--cache-size</span> 102400 redis://:123456@master-ip:6379/1 /home/ubuntu/gluten/gluten_table
    <span class="c">#create a directory for lineitem table path</span>
    <span class="nb">mkdir</span> <span class="nt">-p</span> /home/ubuntu/gluten/gluten_table/lineitem

</code></pre></div></div> <h4 id="preparation"> <a href="#preparation" class="anchor-heading" aria-labelledby="preparation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Preparation </h4> <p>Please refer to <a href="#data-preparation">Data-preparation</a> to generate MergeTree parts data to the lineitem table path: /home/ubuntu/gluten/gluten_table/lineitem.</p> <h4 id="run-spark-thriftserver"> <a href="#run-spark-thriftserver" class="anchor-heading" aria-labelledby="run-spark-thriftserver"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Run Spark Thriftserver </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>spark-3.2.2-bin-hadoop2.7
./sbin/start-thriftserver.sh <span class="se">\</span>
  <span class="nt">--master</span> spark://master-ip:7070 <span class="nt">--deploy-mode</span> client <span class="se">\</span>
  <span class="nt">--driver-memory</span> 16g <span class="nt">--driver-cores</span> 4 <span class="se">\</span>
  <span class="nt">--total-executor-cores</span> 90 <span class="nt">--executor-memory</span> 60g <span class="nt">--executor-cores</span> 15 <span class="se">\</span>
  <span class="nt">--conf</span> spark.driver.memoryOverhead<span class="o">=</span>8G <span class="se">\</span>
  <span class="nt">--conf</span> spark.default.parallelism<span class="o">=</span>90 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.shuffle.partitions<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.minPartitionNum<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.files.maxPartitionBytes<span class="o">=</span>536870912 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.parquet.filterPushdown<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.parquet.enableVectorizedReader<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait.node<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.locality.wait.process<span class="o">=</span>0 <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.columnVector.offheap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.memory.offHeap.size<span class="o">=</span>42949672960 <span class="se">\</span>
  <span class="nt">--conf</span> spark.serializer<span class="o">=</span>org.apache.spark.serializer.JavaSerializer <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.sources.ignoreDataLocality<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.plugins<span class="o">=</span>org.apache.gluten.GlutenPlugin <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.columnarToRow<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.libpath<span class="o">=</span>/path_to_clickhouse_library/libch.so <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.iterator<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.loadarrow<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.hashagg.enablefinal<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.enable.native.validation<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.io.compression.codec<span class="o">=</span>snappy <span class="se">\</span>
  <span class="nt">--conf</span> spark.gluten.sql.columnar.forceShuffledHashJoin<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--conf</span> spark.sql.catalog.spark_catalog<span class="o">=</span>org.apache.spark.sql.execution.datasources.v2.clickhouse.ClickHouseSparkCatalog <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.maxSnapshotLineageLength<span class="o">=</span>20 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.snapshotPartitions<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.properties.defaults.checkpointInterval<span class="o">=</span>5 <span class="se">\</span>
  <span class="nt">--conf</span> spark.databricks.delta.stalenessLimit<span class="o">=</span>3600000
</code></pre></div></div> <h4 id="test-tpc-h-q6-with-jmeter"> <a href="#test-tpc-h-q6-with-jmeter" class="anchor-heading" aria-labelledby="test-tpc-h-q6-with-jmeter"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Test TPC-H Q6 with JMeter </h4> <ul> <li>Create a lineitem table using clickhouse datasource</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">lineitem</span><span class="p">;</span>
    <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">lineitem</span> <span class="p">(</span>
     <span class="n">l_orderkey</span>      <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_partkey</span>       <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_suppkey</span>       <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_linenumber</span>    <span class="nb">bigint</span><span class="p">,</span>
     <span class="n">l_quantity</span>      <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_extendedprice</span> <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_discount</span>      <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_tax</span>           <span class="nb">double</span><span class="p">,</span>
     <span class="n">l_returnflag</span>    <span class="n">string</span><span class="p">,</span>
     <span class="n">l_linestatus</span>    <span class="n">string</span><span class="p">,</span>
     <span class="n">l_shipdate</span>      <span class="nb">date</span><span class="p">,</span>
     <span class="n">l_commitdate</span>    <span class="nb">date</span><span class="p">,</span>
     <span class="n">l_receiptdate</span>   <span class="nb">date</span><span class="p">,</span>
     <span class="n">l_shipinstruct</span>  <span class="n">string</span><span class="p">,</span>
     <span class="n">l_shipmode</span>      <span class="n">string</span><span class="p">,</span>
     <span class="n">l_comment</span>       <span class="n">string</span><span class="p">)</span>
     <span class="k">USING</span> <span class="n">clickhouse</span>
     <span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s1">'MergeTree'</span>
                    <span class="p">)</span>
     <span class="k">LOCATION</span> <span class="s1">'file:///home/ubuntu/gluten/gluten_table/lineitem'</span><span class="p">;</span>
</code></pre></div></div> <ul> <li>Run TPC-H Q6 test with JMeter <ol> <li>Run TPC-H Q6 test 100 times in the first round;</li> <li>Run TPC-H Q6 test 1000 times in the second round;</li> </ol> </li> </ul> <h4 id="performance"> <a href="#performance" class="anchor-heading" aria-labelledby="performance"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Performance </h4> <p>The performance of Gluten + ClickHouse backend increases by <strong>about 1/3</strong>.</p> <div class="table-wrapper"><table> <thead> <tr> <th> </th> <th>70%</th> <th>80%</th> <th>90%</th> <th>99%</th> <th>Avg</th> </tr> </thead> <tbody> <tr> <td>Spark + Parquet</td> <td>590ms</td> <td>592ms</td> <td>597ms</td> <td>609ms</td> <td>588ms</td> </tr> <tr> <td>Spark + Gluten + ClickHouse backend</td> <td>402ms</td> <td>405ms</td> <td>409ms</td> <td>425ms</td> <td>399ms</td> </tr> </tbody> </table></div> <h3 id="new-ci-system"> <a href="#new-ci-system" class="anchor-heading" aria-labelledby="new-ci-system"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> New CI System </h3> <p>https://opencicd.kyligence.com/job/Gluten/job/gluten-ci/ public read-only account：gluten/hN2xX3uQ4m</p> <h3 id="celeborn-support"> <a href="#celeborn-support" class="anchor-heading" aria-labelledby="celeborn-support"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Celeborn support </h3> <p>Gluten with clickhouse backend supports <a href="https://github.com/apache/celeborn">Celeborn</a> as remote shuffle service. Currently, the supported Celeborn versions are <code class="language-plaintext highlighter-rouge">0.3.x</code>, <code class="language-plaintext highlighter-rouge">0.4.x</code> and <code class="language-plaintext highlighter-rouge">0.5.0</code>.</p> <p>Below introduction is used to enable this feature.</p> <p>First refer to this URL(https://github.com/apache/celeborn) to setup a celeborn cluster.</p> <p>When compiling the Gluten Java module, it’s required to enable <code class="language-plaintext highlighter-rouge">celeborn</code> profile, as follows:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mvn clean package <span class="nt">-Pbackends-clickhouse</span> <span class="nt">-Pspark-3</span>.3 <span class="nt">-Pceleborn</span> <span class="nt">-DskipTests</span>
</code></pre></div></div> <p>Then add the Spark Celeborn Client packages to your Spark application’s classpath(usually add them into <code class="language-plaintext highlighter-rouge">$SPARK_HOME/jars</code>).</p> <ul> <li>Celeborn: celeborn-client-spark-3-shaded_2.12-[celebornVersion].jar</li> </ul> <p>Currently to use Gluten following configurations are required in <code class="language-plaintext highlighter-rouge">spark-defaults.conf</code></p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark.shuffle.manager org.apache.spark.shuffle.gluten.celeborn.CelebornShuffleManager

<span class="c"># celeborn master</span>
spark.celeborn.master.endpoints clb-master:9097

spark.shuffle.service.enabled <span class="nb">false</span>

<span class="c"># options: hash, sort</span>
<span class="c"># Hash shuffle writer use (partition count) * (celeborn.push.buffer.max.size) * (spark.executor.cores) memory.</span>
<span class="c"># Sort shuffle writer uses less memory than hash shuffle writer, if your shuffle partition count is large, try to use sort hash writer.</span>
spark.celeborn.client.spark.shuffle.writer <span class="nb">hash</span>

<span class="c"># We recommend setting spark.celeborn.client.push.replicate.enabled to true to enable server-side data replication</span>
<span class="c"># If you have only one worker, this setting must be false </span>
<span class="c"># If your Celeborn is using HDFS, it's recommended to set this setting to false</span>
spark.celeborn.client.push.replicate.enabled <span class="nb">true</span>

<span class="c"># Support for Spark AQE only tested under Spark 3</span>
<span class="c"># we recommend setting localShuffleReader to false to get better performance of Celeborn</span>
spark.sql.adaptive.localShuffleReader.enabled <span class="nb">false</span>

<span class="c"># If Celeborn is using HDFS</span>
spark.celeborn.storage.hdfs.dir hdfs://&lt;namenode&gt;/celeborn

<span class="c"># If you want to use dynamic resource allocation,</span>
<span class="c"># please refer to this URL (https://github.com/apache/celeborn/tree/main/assets/spark-patch) to apply the patch into your own Spark.</span>
spark.dynamicAllocation.enabled <span class="nb">false</span>
</code></pre></div></div> <h3 id="columnar-shuffle-mode"> <a href="#columnar-shuffle-mode" class="anchor-heading" aria-labelledby="columnar-shuffle-mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Columnar shuffle mode </h3> <p>We have two modes of columnar shuffle</p> <ol> <li>prefer cache</li> <li>prefer spill</li> </ol> <p>Switch through the configuration <code class="language-plaintext highlighter-rouge">spark.gluten.sql.columnar.backend.ch.shuffle.preferSpill</code>, the default is <code class="language-plaintext highlighter-rouge">false</code>, enable prefer cache shuffle.</p> <p>In the prefer cache mode, as much memory as possible will be used to cache the shuffle data. When the memory is insufficient, spark will actively trigger the memory spill. You can also specify the threshold size through <code class="language-plaintext highlighter-rouge">spark.gluten.sql.columnar.backend.ch.spillThreshold</code> to Limit memory usage. The default value is <code class="language-plaintext highlighter-rouge">0MB</code>, which means no limit on memory usage.</p> </main> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <a href="https://incubator.apache.org/"><img src="/assets/images/apache-incubator.svg" style="width:300px"></a> <p class="text-small text-grey-dk-100 mb-0">Copyright © 2024 The Apache Software Foundation, Licensed under the Apache License, Version 2.0. Apache Gluten, Gluten, Apache, the Apache feather logo, and the Apache Gluten project logo are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.</p> <p class="text-small text-grey-dk-100 mb-0">Apache Gluten is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p> <p class="text-small text-grey-dk-100 mb-0"><a href="https://privacy.apache.org/policies/privacy-policy-public.html">Privacy Policy</a></p> <div class="d-flex mt-2"> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
